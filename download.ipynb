{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install fitz\n",
    "!pip install pdf2image\n",
    "\n",
    "\n",
    "!pip install pytesseract\n",
    "!pip uninstall frontend -y\n",
    "!pip install --upgrade pymupdf\n",
    "!pip install openai\n",
    "import fitz\n",
    "print(fitz.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9bb221",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import statistics\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "import base64\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"#YOUR API KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b83e4",
   "metadata": {},
   "source": [
    "### Download and convert to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"earnings_reports.csv\")\n",
    "df = df[df[\"ticker\"].notna()]\n",
    "df[\"ticker\"] = df[\"ticker\"].str.replace(\":\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also convert to HTML using pdf parser and OCR.\n",
    "# However in the end we use the pdf directly and rely on OpenAI's extraction.\n",
    "\n",
    "QUARTER = \"Q1\"\n",
    "\n",
    "def extract_text_pymupdf(pdf_path):\n",
    "    \"\"\"Try extracting text with PyMuPDF.\"\"\"\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        try:\n",
    "            text += page.get_text(\"text\") + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting page {page.number} in {pdf_path}: {e}\")\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_ocr(pdf_path):\n",
    "    \"\"\"Fallback OCR if no text found.\"\"\"\n",
    "    print(f\"‚ö†Ô∏è Running OCR for {pdf_path} (image-based PDF)...\")\n",
    "    text = \"\"\n",
    "    images = convert_from_path(pdf_path)\n",
    "    for i, img in enumerate(images, start=1):\n",
    "        try:\n",
    "            text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR failed on page {i} in {pdf_path}: {e}\")\n",
    "    return text.strip()\n",
    "\n",
    "results = []\n",
    "\n",
    "# Process each PDF\n",
    "for i, row in df.iterrows():\n",
    "    if QUARTER == \"Q2\":\n",
    "        url = row[\"report_source\"]\n",
    "    elif QUARTER == \"Q1\":\n",
    "        url = row[\"Q1 2025 report\"]\n",
    "    elif QUARTER == \"Q4_2024\":\n",
    "        url = row[\"Q4 2024 report\"]\n",
    "    ticker = row['ticker']   # <-- adjust column name if needed\n",
    "    subfolder = \"\"\n",
    "    if QUARTER != \"Q2\":\n",
    "        subfolder = QUARTER\n",
    "    # Create all required folders\n",
    "    for folder in [\"pdfs\", \"htmls\", \"ocr\"]:\n",
    "        os.makedirs(os.path.join(folder, subfolder), exist_ok=True)\n",
    "\n",
    "    pdf_filename = os.path.join(\"pdfs\", subfolder, f\"file_{ticker}.pdf\")\n",
    "    html_filename = os.path.join(\"htmls\", subfolder, f\"file_{ticker}.html\")\n",
    "    ocr_filename = os.path.join(\"ocr\", subfolder, f\"file_{ticker}.html\")\n",
    "    \n",
    "    if pd.isna(url):\n",
    "        print(f\"‚ùå No URL for {ticker}\")\n",
    "        continue\n",
    "    if 'drive.google.com' in url:\n",
    "        parts = url.split('/d/')\n",
    "        if len(parts) > 1:\n",
    "            file_id = parts[1].split('/')[0]\n",
    "            url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "    if not url or (os.path.exists(pdf_filename) and valid_file[f\"{QUARTER}_{ticker}\"]):\n",
    "        continue\n",
    "    try:\n",
    "        # Download PDF\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(pdf_filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"‚úÖ Downloaded: {pdf_filename}\")\n",
    "\n",
    "        # Extract text (PyMuPDF and OCR)\n",
    "        text_pymupdf = extract_text_pymupdf(pdf_filename)\n",
    "        text_ocr = extract_text_ocr(pdf_filename)\n",
    "        \n",
    "        if text_ocr:\n",
    "            html = f\"<html><body><pre>{text_ocr}</pre></body></html>\"\n",
    "            \n",
    "            with open(ocr_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "\n",
    "            print(f\"üìÑ Extracted text ‚Üí {html_filename} and {ocr_filename}\")\n",
    "            results.append({\"file\": pdf_filename, \"status\": \"success\"})\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No text could be extracted using ocr from {pdf_filename}\")\n",
    "            results.append({\"file\": pdf_filename, \"status\": \"no text\"})\n",
    "\n",
    "        # Save to HTML (htmls/ and static/)\n",
    "        if text_pymupdf:\n",
    "            html = f\"<html><body><pre>{text_pymupdf}</pre></body></html>\"\n",
    "\n",
    "            with open(html_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(html)\n",
    "\n",
    "\n",
    "            print(f\"üìÑ Extracted text ‚Üí {html_filename} and {ocr_filename}\")\n",
    "            results.append({\"file\": pdf_filename, \"status\": \"success\"})\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No text could be extracted using pymupdf from {pdf_filename}\")\n",
    "            results.append({\"file\": pdf_filename, \"status\": \"no text\"})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {url}: {e}\")\n",
    "        results.append({\"file\": pdf_filename, \"status\": f\"error: {e}\"})\n",
    "\n",
    "log_path = \"extraction_log.csv\"\n",
    "pd.DataFrame(results).to_csv(log_path, index=False)\n",
    "print(f\"\\nüìä Extraction log saved to {log_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebf489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_path = \"htmls/file_1.html\"\n",
    "\n",
    "with open(html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "text = soup.get_text()\n",
    "\n",
    "# Print everything (can be very long!)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    reasoning={\"effort\": \"medium\"},\n",
    "    input=[{\"role\": \"user\", \"content\": \"Hello, are you working?\"}]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ee964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name: str):\n",
    "    if os.path.exists(f'data/{file_name}'):\n",
    "        with open(f'data/{file_name}', \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_pickle(file_name: str, data):\n",
    "    with open(f'data/{file_name}', \"wb\") as f:\n",
    "        pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177bcaec",
   "metadata": {},
   "source": [
    "## Upload Files to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = load_pickle(f'ticker_file_id_map.pickle')\n",
    "QUARTER = \"Q1\"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    id = f\"{QUARTER}_{ticker}\"\n",
    "    if id in ids and valid_file[id] is not False:\n",
    "        continue\n",
    "    pdf_path = f\"pdfs/{QUARTER}/file_{ticker}.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        continue\n",
    "    ids[id] = client.files.create(\n",
    "        file=(QUARTER + \"_\" + pdf_path.split(\"/\")[-1], open(pdf_path, 'rb').read()),\n",
    "        purpose=\"user_data\",\n",
    "    ).id\n",
    "\n",
    "save_pickle(f'ticker_file_id_map.pickle', ids)\n",
    "len(ids), ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file = load_pickle(f'valid_file.pickle')\n",
    "\n",
    "QUARTER = \"Q1\"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    id = f\"{QUARTER}_{ticker}\"\n",
    "    if id not in ids or (id in valid_file and valid_file[id] is not False):\n",
    "        continue\n",
    "    print(f\"Processing {id}\")\n",
    "    ending_month = \"\"\n",
    "    match QUARTER:\n",
    "        case \"Q1\":\n",
    "            ending_month = \"March 2025\"\n",
    "        case \"Q2\":\n",
    "            ending_month = \"June 2025\"\n",
    "        case \"Q4_2024\":\n",
    "            ending_month = \"December 2024\"\n",
    "    prompt = f\"Does this file contain decent amount of information about earnings, e.g. not one paragraph but actual numbers of respective changes in metrics between quarters and so on? Answer yes or no on the last line. Also answer no if the file doesn't cover the period ending {ending_month}.\"\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    #temperature=0.7,  # keep >0 so you see variation\n",
    "                input=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"input_text\", \"text\": prompt},\n",
    "                            {\n",
    "                                \"type\": \"input_file\",\n",
    "                                \"file_id\": ids[id],\n",
    "                            },\n",
    "                        ],\n",
    "                    }]\n",
    "            )\n",
    "    except Exception as e:\n",
    "        if \"The file type you uploaded is not supported\" in str(e):\n",
    "            print(f\"Ticker {id} has an unsupported file type\")\n",
    "            valid_file[id] = False\n",
    "        else:\n",
    "            print(f\"Error processing {id}: {e}\")\n",
    "        continue\n",
    "    answer = response.output_text.strip().split(\"\\n\")[-1]\n",
    "    if \"no\" in answer.lower():\n",
    "        print(f\"Ticker {id} does not have earnings information\")\n",
    "        valid_file[id] = False\n",
    "    elif \"yes\" in answer.lower():\n",
    "        valid_file[id] = True\n",
    "    else:\n",
    "        print(f\"Ticker {id} has an invalid answer: {answer}\")\n",
    "\n",
    "save_pickle(f'valid_file.pickle', valid_file)\n",
    "\n",
    "for id, is_valid in valid_file.items():\n",
    "    if is_valid is False:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40315d79",
   "metadata": {},
   "source": [
    "## Validate curated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c430376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the estimates only contain expectations\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    estimates = row['Estimates']\n",
    "    prompt = f\"Evaluate if the following text contains only comparisons to expectations or also information on how the stock has moved afterwards. Answer simply 'Only expectations' or 'Also price movement'. Text: {estimates}\"\n",
    "    response = client.responses.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    #temperature=0.7,  # keep >0 so you see variation\n",
    "                input=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"input_text\", \"text\": prompt},\n",
    "                        ],\n",
    "                    }]\n",
    "            )\n",
    "    print(f\"{ticker} - {response.output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d576bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify etimations\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    estimates = row['Estimates.2']\n",
    "    prompt = f\"Evaluate if the following expectations suggest Beat, Disappoint or Meet. Answer simply 'Beat', 'Disappoint' or 'Meet' or 'Unknown'. Text: {estimates}\"\n",
    "    response = client.responses.create(\n",
    "                    model=\"gpt-5.1\",\n",
    "                    #temperature=0.7,  # keep >0 so you see variation\n",
    "                input=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"input_text\", \"text\": prompt},\n",
    "                        ],\n",
    "                    }]\n",
    "            )\n",
    "    print(f\"{response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988691a9",
   "metadata": {},
   "source": [
    "## Traditional accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "45c20472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up: 0.5272727272727272\n",
      "down: 0.3404255319148936\n",
      "flat: 0.16666666666666666\n",
      "Accuracy: 0.4\n",
      "evals: 120\n"
     ]
    }
   ],
   "source": [
    "# S&P500 change\n",
    "\n",
    "\n",
    "matches = 0\n",
    "evals = 0\n",
    "matches_per_category = defaultdict(int)\n",
    "evals_per_category = defaultdict(int)\n",
    "threshold = 0.009\n",
    "for suffix in [\"\", \".1\", \".2\"]:\n",
    "    for i, row in df.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        sap500_before_close = row[f'sap500_before_close{suffix}']\n",
    "        sap500_after_open = row[f'sap500_after_open{suffix}']\n",
    "        mapped_movement = \"\"\n",
    "        if abs(sap500_before_close - sap500_after_open)/sap500_before_close >= threshold:\n",
    "            #print(f'{ticker} - {suffix} - {sap500_before_close} - {sap500_after_open}')\n",
    "            mapped_movement = \"flat\"\n",
    "        elif sap500_before_close < sap500_after_open:\n",
    "            mapped_movement = \"up\"\n",
    "        else:\n",
    "            mapped_movement = \"down\"\n",
    "        real_movement = row[f'Change on open{suffix}'].lower()\n",
    "        if mapped_movement == real_movement:\n",
    "            matches += 1\n",
    "            matches_per_category[real_movement] += 1\n",
    "        evals += 1\n",
    "        evals_per_category[real_movement] += 1\n",
    "\n",
    "for category in [\"up\", \"down\", \"flat\"]:\n",
    "    print(f\"{category}: {matches_per_category[category]/evals_per_category[category]}\")\n",
    "print(f\"Accuracy: {matches/evals}\")\n",
    "print(f'evals: {evals}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df02b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44954128440366975\n",
      "\n",
      "Beat: 0.40789473684210525\n",
      "Disappoint: 0.6296296296296297\n",
      "Meet: 0.16666666666666666\n",
      "up: 0.775\n",
      "down: 0.3269230769230769\n",
      "flat: 0.058823529411764705\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of analysts expectations matching the actual movement\n",
    "\n",
    "matches = 0\n",
    "evals = 0\n",
    "matches_per_category = defaultdict(int)\n",
    "evals_per_category = defaultdict(int)\n",
    "for suffix in [\"\", \".1\", \".2\"]:\n",
    "    for i, row in df.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        sentiment = row[f'estimates_sentiment{suffix}']\n",
    "        if sentiment == \"Unknown\":\n",
    "            continue\n",
    "        mapped_movement = \"\"\n",
    "        if sentiment == \"Beat\":\n",
    "            mapped_movement = \"up\"\n",
    "        elif sentiment == \"Disappoint\":\n",
    "            mapped_movement = \"down\"\n",
    "        elif sentiment == \"Meet\":\n",
    "            mapped_movement = \"flat\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid sentiment: {sentiment}\")\n",
    "        \n",
    "        real_movement = row[f'Change on close{suffix}'].lower()\n",
    "        if mapped_movement == real_movement:\n",
    "            matches += 1\n",
    "            matches_per_category[sentiment] += 1\n",
    "            matches_per_category[real_movement] += 1\n",
    "        evals += 1\n",
    "        evals_per_category[sentiment] += 1\n",
    "        evals_per_category[real_movement] += 1\n",
    "\n",
    "print(f\"Accuracy: {matches/evals}\")\n",
    "print()\n",
    "for category in [\"Beat\", \"Disappoint\", \"Meet\", \"up\", \"down\", \"flat\"]:\n",
    "    print(f\"{category}: {matches_per_category[category]/evals_per_category[category]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
