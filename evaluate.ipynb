{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82affc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import statistics\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from collections import defaultdict\n",
    "import base64\n",
    "import os\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a257ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_name: str):\n",
    "    if os.path.exists(f'data/{file_name}'):\n",
    "        with open(f'data/{file_name}', \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return defaultdict(list)\n",
    "\n",
    "def save_pickle(file_name: str, data):\n",
    "    with open(f'data/{file_name}', \"wb\") as f:\n",
    "        pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b23084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and remove rows where 'ticker' is NaN\n",
    "df = pd.read_csv(\"earnings_reports.csv\")\n",
    "df = df[df[\"ticker\"].notna()]\n",
    "file_ids = load_pickle(f'ticker_file_id_map.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28804a31",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce35a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(current_price: float, is_thinking: bool):\n",
    "    specific_prompt = \" and how this is calculated and the rationales behind?\\nExplain briefly why. \" if is_thinking else \". Only output price and up or down.\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial analyst.\n",
    "\n",
    "    Question:\n",
    "    Based on the attached earnings report, what is the prediction for 1) how the company's stock price will move the next day (gap up, gap down, or flat) \n",
    "    2) Given the current close price on the day of release is {current_price:.2f}, \n",
    "    Predict for the next day stock price{specific_prompt}\n",
    "    Pre last sentence on a new line put a number (stock price) you estimate to open on.\n",
    "    Last sentence on a new line only say up or down or float. \n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "print(get_prompt(12.2109,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d559dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prediction(response):\n",
    "    output = response.output_text.strip()\n",
    "    # print(\"Raw model output:\\n\", output) \n",
    "\n",
    "    # Split on newlines\n",
    "    lines = [line.strip() for line in output.splitlines() if line.strip()]  # removes empty strings\n",
    "    print(\"DEBUG lines\", lines)\n",
    "\n",
    "    # Extract values\n",
    "    predicted_price = lines[-2].strip() if len(lines) > 1 else None\n",
    "    direction = lines[-1].strip(\" *\").lower() if len(lines) > 0 else None\n",
    "\n",
    "    if \":\" in predicted_price:\n",
    "        predicted_price = predicted_price.split(\":\")[1].strip()\n",
    "    if \":\" in direction:\n",
    "        direction = direction.split(\":\")[1].strip(\" *\")\n",
    "    if \")\" in predicted_price:\n",
    "        predicted_price = predicted_price.split(\")\")[1].strip()\n",
    "    if \"at\" in predicted_price:\n",
    "        predicted_price = predicted_price.split(\"at\")[-1].strip()\n",
    "    \n",
    "    if \")\" in direction:\n",
    "        direction = direction.split(\")\")[1].strip()\n",
    "\n",
    "    assert direction in [\"up\", \"down\", \"flat\"], f\"Direction {direction} is not valid\"\n",
    "\n",
    "    if predicted_price[0] == '$':\n",
    "        predicted_price = predicted_price[1:]\n",
    "    #print(\"DEBUG prediction\", predicted_price)\n",
    "    return float(predicted_price.strip(' .*')), direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_prediction(row: pd.Series, is_thinking: bool, runs: int, model: str, predictions: defaultdict):\n",
    "    client = OpenAI()\n",
    "    prices = []\n",
    "    directions = []\n",
    "    ticker = row['ticker']\n",
    "    last_price = row['close_price_release_day']\n",
    "\n",
    "    k = (ticker, model, is_thinking)\n",
    "    \n",
    "    while len(predictions[k]) < runs:\n",
    "        response = client.responses.create(\n",
    "            model=model,\n",
    "            #temperature=0.7,  # keep >0 so you see variation\n",
    "            input=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"input_text\", \"text\": get_prompt(last_price, is_thinking)},\n",
    "                        {\n",
    "                            \"type\": \"input_file\",\n",
    "                            \"file_id\": file_ids[ticker],\n",
    "                        },\n",
    "                    ],\n",
    "                }]\n",
    "        )\n",
    "        predicted_price, direction = extract_prediction(response)\n",
    "\n",
    "        predictions[k].append((response.output_text.strip(), predicted_price, direction))\n",
    "\n",
    "        if predicted_price is not None:\n",
    "            prices.append(predicted_price)\n",
    "        if direction:\n",
    "            directions.append(direction)\n",
    "        #print(f\"Run {i+1}: {predicted_price}, {direction}\")\n",
    "\n",
    "    # Compute average and most common direction\n",
    "    avg_price = statistics.mean(prices) if prices else None\n",
    "    most_common_direction = max(set(directions), key=directions.count) if directions else None\n",
    "\n",
    "    print(\"\\n--- Final Results ---\")\n",
    "    print(f\"Average predicted price: {avg_price}, real post price {row['nextday_open']}, pre-price {last_price}\")\n",
    "    print(f\"Most common direction: {most_common_direction}\")\n",
    "    \n",
    "    return avg_price, most_common_direction\n",
    "test = defaultdict(list)\n",
    "get_avg_prediction(df.iloc[1], False, 2, 'gpt-4o-mini', test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_predictions(test_dict):\n",
    "    # Flatten the test dict into one record per key, merging all predictions into one row per k\n",
    "    records = []\n",
    "    for key, pred_list in test_dict.items():\n",
    "        # key is a tuple (ticker, model, is_thinking)\n",
    "        record = {\n",
    "            \"ticker\": key[0],\n",
    "            \"model\": key[1],\n",
    "            \"is_thinking\": key[2],\n",
    "            \"close_price_release_day\": df.loc[df['ticker'] == key[0], 'close_price_release_day'].iloc[0],\n",
    "            \"nextday_open\": df.loc[df['ticker'] == key[0], 'nextday_open'].iloc[0],\n",
    "            \"movement\": \"up\" if df.loc[df['ticker'] == key[0], 'nextday_open'].iloc[0] > df.loc[df['ticker'] == key[0], 'close_price_release_day'].iloc[0] else \"down\"\n",
    "        }\n",
    "        # Merge all predictions into columns for this record\n",
    "        prices = []\n",
    "        directions = []\n",
    "        for i, tup in enumerate(pred_list, 1):\n",
    "            record[f\"text_{i}\"] = tup[0]\n",
    "            record[f\"predicted_price_{i}\"] = tup[1]\n",
    "            record[f\"direction_{i}\"] = tup[2]\n",
    "            if tup[1] is not None:\n",
    "                prices.append(tup[1])\n",
    "            if tup[2]:\n",
    "                directions.append(tup[2])\n",
    "        # Add average prediction, median prediction and majority direction\n",
    "        record[\"avg_predicted_price\"] = statistics.mean(prices) if prices else None\n",
    "        record[\"median_predicted_price\"] = statistics.median(prices) if prices else None\n",
    "        record[\"majority_direction\"] = max(set(directions), key=directions.count) if directions else None\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    df_out = pd.DataFrame(records)\n",
    "    # Move 'median_predicted_price' after 'movement'\n",
    "    cols = list(df_out.columns)\n",
    "    cols.remove('median_predicted_price')\n",
    "    movement_idx = cols.index('movement')\n",
    "    cols.insert(movement_idx + 1, 'median_predicted_price')\n",
    "    df_out = df_out[cols]\n",
    "    return df_out\n",
    "\n",
    "df_test = flatten_predictions(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b40798",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f458f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = load_pickle('predictions.pickle')\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "runs = 3\n",
    "is_thinking = False\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    k = (ticker, model, is_thinking)\n",
    "    if k in predictions and len(predictions[k]) >= runs:\n",
    "        continue\n",
    "    assert ticker in file_ids, \"Ticker not in file_ids\"\n",
    "    print(f\"Processing {ticker}, row {i} of {len(df)}\")\n",
    "    get_avg_prediction(row, is_thinking, runs, model, predictions)\n",
    "\n",
    "save_pickle('predictions.pickle', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the percentage of 'up' movements in predictions and in majority_direction\n",
    "\n",
    "flat_df = flatten_predictions(predictions)\n",
    "\n",
    "# Percentage of 'up' in movement\n",
    "up_count = (flat_df[\"movement\"] == \"up\").sum()\n",
    "total_count = flat_df[\"movement\"].notna().sum()\n",
    "percent_up = (up_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "# Percentage of 'up' in majority_direction\n",
    "majority_up_count = (flat_df[\"majority_direction\"] == \"up\").sum()\n",
    "majority_total_count = flat_df[\"majority_direction\"].notna().sum()\n",
    "percent_majority_up = (majority_up_count / majority_total_count) * 100 if majority_total_count > 0 else 0\n",
    "\n",
    "# Percentage where movement and majority_direction match\n",
    "match_mask = (flat_df[\"movement\"].notna()) & (flat_df[\"majority_direction\"].notna())\n",
    "matches = (flat_df[\"movement\"][match_mask] == flat_df[\"majority_direction\"][match_mask]).sum()\n",
    "total_matches = match_mask.sum()\n",
    "percent_matches = (matches / total_matches) * 100 if total_matches > 0 else 0\n",
    "\n",
    "# Hypothesis test: is the proportion of matches statistically significantly different from random chance?\n",
    "# Null hypothesis: proportion of matches = p_null\n",
    "p_null = 0.5  # e.g., random 50/50 guessing\n",
    "if total_matches > 0:\n",
    "    # Try to use the now-recommended 'stats.binomtest', and fall back for older scipy versions\n",
    "    p_result = stats.binomtest(matches, total_matches, p_null, alternative='two-sided')\n",
    "    p_value = p_result.pvalue\n",
    "    # Range: calculate 95% confidence interval for the proportion\n",
    "    ci_low, ci_upp = stats.binom.interval(0.95, total_matches, matches/total_matches, loc=0)\n",
    "    ci_low = (ci_low / total_matches) * 100 if total_matches > 0 else 0\n",
    "    ci_upp = (ci_upp / total_matches) * 100 if total_matches > 0 else 0\n",
    "else:\n",
    "    p_value = None\n",
    "    ci_low, ci_upp = None, None\n",
    "\n",
    "print(f\"Percentage of 'up' movements: {percent_up:.2f}%\")\n",
    "print(f\"Percentage of 'up' majority_direction: {percent_majority_up:.2f}%\")\n",
    "print(f\"Percentage where movement and majority_direction match: {percent_matches:.2f}%\")\n",
    "if p_value is not None:\n",
    "    print(f\"p-value of match proportion vs 0.5: {p_value:.4f}\")\n",
    "    print(f\"95% confidence interval for match percentage: [{ci_low:.2f}%, {ci_upp:.2f}%]\")\n",
    "else:\n",
    "    print(\"Not enough data for p-value/confidence interval calculation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_predictions(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
